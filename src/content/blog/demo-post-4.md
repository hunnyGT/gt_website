---
publishDate: 'Nov 28, 2019'
title: 'Unlocking the Power of Neural Networks: A Comprehensive Exploration into the Basics of Artificial Neural Networks'
description: 'Lorem ipsum dolor sit amet'
excerpt: 'Sint sit cillum pariatur eiusmod nulla pariatur ipsum. Sit laborum anim qui mollit tempor pariatur nisi minim dolor. Aliquip et adipisicing sit sit fugiat'
image: 'https://miro.medium.com/v2/1*UwF9hZ8rdmioHfbsmcJfjw.jpeg'
tags: [markdown, blog]
---

## <a name="Headings"></a>Basics of Neural Network

Artificial Intelligence, Deep Learning & Machine Learning. Like everyone I was also very much impressed with these terms, And couple of months back I got an opportunity to work on a chatbot so, <a href="https://www.youtube.com/watch?v=wL-6_e0pYbU">I developed a chatbot using RASA</a>(Machine learning tools for developers to build contextual chatbots and assistants) and my excitement on AI and ML got increased. I started exploring more on these topics, then I came to know about how ML and DL works. On a high level it’s higher secondary math’s and biological neurons, which play’s a major role.

## Neural Network work exactly how our brain works

![Alt Text](https://img.mit.edu/files/images/202211/MIT-Neural-Networks-SL.gif)

Neurons are cells within our nervous system that transmit information to other nerve cells, muscle, or gland cells.

Likewise Neurons in Neural Network are also interconnected which passes information from one neuron to another.

![Alt Text](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uxYy44UZ6fGIWaHrGQqF9g.png)

Input 0 and Input 1 are the placeholders for inputs, placeholders will take the data and pass it on to other neurons, now neurons will use Activation function, which will basically provide solution in 0’s or 1’s.

### Enters a new term “Activation Function ”, what exactly is Activation function?

In general term Activation function does the calculation of the input data and provides a solution for the next neurons. Activation function play’s a very important role in ML and AI, it helps the neurons to learn and predict by using various Mathematical functions such as:

1. Linear Function
2. Sigmoid Function
3. Tanh Function
4. ReLU
5. Softmax Function

![Alt Text](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZafDv3VUm60Eh10OeJu1vw.png)

Choosing a right Activation function depends upon how your problems are, when you want the model to learn fast and accurate ,you choose activation function wisely. For simple calculation you can choose Sigmoid function or Tanh Function.

These day’s most widely used activation function is ReLU, it is basically used inside he Hidden layers.

A hidden layer in an artificial neural network is a layer in between input layers and output layers.

![Alt Text](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nX6L9rclTnx0Hph5i01wzg.jpeg)

#### In a nutshell

So to sum up, neural networks are the neurons which are interconnected to each other in a hierarchical order, Each neurons uses an activation function to learn and understand your data, and also passes through another neurons.

#MachineLearning #Artificial #NeuralNetwork #NeuralNetworks #DeepLearning

[[Move to top]](#top)
